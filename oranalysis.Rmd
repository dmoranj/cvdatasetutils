---
title: "Object Recognition Dataset Analysis"
output: beamer_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(dpi = 72)
knitr::opts_chunk$set(dev="png")

library(tidyr)
library(dplyr)
library(ggplot2)
library(splitstackshape)
library(bnlearn)
library(stringr)

set.seed(1)
```

``` {r, include=FALSE}
vocDataPath <- './analytics/voc_df.csv'
vgDataPath <- './analytics/vg_df.csv'
cocoDataPath <- './analytics/coco_df.csv'
restrictedDataPath <- './analytics/restricted_df.csv'
ad20kDataPath <- './analytics/ad20k_df.csv'

vocData <- read.csv(vocDataPath)
vgData <- read.csv(vgDataPath)
cocoData <- read.csv(cocoDataPath)
restrictedData <- read.csv(restrictedDataPath)
ad20kData <- read.csv(ad20kDataPath)
```

```{r, include=FALSE}
vocFragment <- vocData %>%
  select(imageId = img, x, y, w, h, label = names ) %>%
  mutate(dataset = "VOC", imageId=as.character(imageId))

restrictedFragment <- restrictedData %>%
  select(imageId = image_id, x, y, w, h, label = name ) %>%
  mutate(dataset = "Restricted", imageId=as.character(imageId), x = x + w/2, y = y + h/2)

vgFragment <- vgData %>%
  select(imageId = img, x, y, w, h, label = names ) %>%
  mutate(dataset = "VG", imageId=as.character(imageId), x = x + w/2, y = y + h/2)

cocoFragment <- cocoData %>%
  select(imageId = image_id, x, y, w, h, label = name ) %>%
  mutate(dataset = "COCO", imageId=as.character(imageId), x = x + w/2, y = y + h/2)

ad20kFragment <- ad20kData %>%
  mutate(x = x / imgWidth, y = y/imgHeight, h = h/imgHeight, w = w/imgWidth) %>%
  select(imageId = image_id, x, y, w, h, label ) %>%
  mutate(dataset = "AD20K", imageId=as.character(imageId), x = x + w/2, y = y + h/2)

globalData <- rbind(vocFragment, vgFragment, cocoFragment, restrictedFragment, ad20kFragment) %>%
  mutate(imageId = as.factor(imageId), dataset=as.factor(dataset), label=as.factor(label))

```

# Summary

This document contains the following sections:

* An introduction to the problem we are addressing
* A brief study of the general characteristics of each datasets, with regard to Object Detection and classification
* An analysis of four LDA models that were trained with the object content of each of the images to group the images into topics
* An analysis of how to exploit these topics for improved object recognition

# Introduction

Object recognition. Use of non-object independence for improve detection


# The Datasets

Four datasets were compared along this document:

* Three well-stablished Object Recognition datasets: Pascal VOC, Microsot COCO and Visual Genome
* A restricted and cleaned version of Visual Genome. As it will be presented in the following section, from the studied datasets, Visual Genome is the
most densely anotated and contains the higher number of classes, but this comes at the price of a lot of annotation noise. To improve its characteristics,
a cleaned version (RestrictedVG) was created with the following characteristics:
  * Its includes only objects whose labels could be described by exactly one Wordnet Synset
  * It doesn't include objects with an area smaller than a given threshold
  * Among those, it includes only the 1000 classes with more instances
  * It doesn't include images with less than 10 classes
  
# General statistics

```{r}
generalStats <- globalData %>%
  group_by(dataset) %>%
  summarize(images=n_distinct(imageId), objects=n(), labels=n_distinct(label), objPerImg=objects/images) %>%
  arrange(desc(images), objects)

knitr::kable(generalStats)
```

Things to remark:

* VOC has a really low number of objects per image, on average, making it improbable to benefit from object context.
* The number of labels in VG is based on exact string matching, but VG's labels are noisy and contain typos or variants. The real number is probably way lower
  but there's no clear way of cleaning it.

# Object Location

```{r}
globalData <- globalData %>%
  mutate(area = w * h)
```

```{r, dpi=72, fig.width=12, fig.height=10}
sampledData <- globalData %>%
  group_by(dataset) %>%
  sample_n(2000)

sampledData %>%
  select(dataset, x, y) %>%
  ggplot(aes(x = x, y = y, fill=dataset)) +
    facet_wrap(~ dataset) +
    geom_point(shape=21, alpha=0.2)
```

# Object Size

```{r, dpi=72, fig.width=12, fig.height=10}
sampledData %>%
  select(dataset, w, h, area) %>%
  ggplot(aes(x = w, y = h, fill=dataset)) +
    facet_wrap(~ dataset) +
    geom_point(shape=21, alpha=0.2)
```

# Object Area vs Location

```{r, dpi=72, fig.width=12, fig.height=10}
sampledData %>%
  select(dataset, x, y, area) %>%
  ggplot(aes(x = x, y = y, color=area)) +
    facet_wrap(~ dataset) +
    geom_point(size=1, alpha=0.65)
```

# Global area distribution

```{r, dpi=72, fig.width=12, fig.height=3}
globalData %>%
  filter(area <= 1, area > 0) %>%
  ggplot(aes(x=dataset, y=area, fill=dataset)) +
    geom_boxplot() +
    coord_flip()
```

This graph shows areas in the normalized range [0, 1]. Some examples where remove from VG with areas greater than one or smaller than zero.

# Top 10 objects with bigger mean area

```{r, dpi=72, fig.width=12, fig.height=8}
areaSummaries <- globalData %>%
  select(dataset, label, area) %>%
  group_by(dataset, label) %>%
  summarize(areaMean=mean(area)) %>%
  arrange(desc(areaMean)) %>%
  mutate(id=sequence(n())) %>%
  mutate(rank = rank(desc(areaMean))) %>%
  filter(id <= 10)

globalData %>%
  select(dataset, label, area) %>%
  semi_join(areaSummaries, by=c('dataset', 'label')) %>%
  ggplot(aes(x=label, y=area, fill=label)) +
    geom_boxplot(alpha=0.6) +
    facet_wrap(~ dataset, ncol=2, scales = "free") +
    theme(axis.text.x = element_text(angle = 45, hjust=1)) +
    coord_flip()
```

# Top 10 objects with smaller mean area

```{r, dpi=72, fig.width=12, fig.height=8}
areaSummaries <- globalData %>%
  select(dataset, label, area) %>%
  group_by(dataset, label) %>%
  summarize(areaMean=mean(area)) %>%
  arrange(desc(areaMean)) %>%  
  mutate(id=sequence(n())) %>%
  mutate(rank = rank(desc(areaMean))) %>%
  filter(id > max(id) - 10)

globalData %>%
  select(dataset, label, area) %>%
  semi_join(areaSummaries, by=c('dataset', 'label')) %>%
  ggplot(aes(x=label, y=area, fill=label)) +
    geom_boxplot(alpha=0.6) +
    facet_wrap(~ dataset, ncol=2, scales="free") +
    theme(axis.text.x = element_text(angle = 45, hjust=1)) +
    coord_flip()
```

# Top 20 most frequent label distribution

```{r, dpi=72, fig.width=12, fig.height=14}
distributionSummaries <- globalData %>%
  select(dataset, label, area) %>%
  group_by(dataset, label) %>%
  summarize(number=n()) %>%
  arrange(desc(number)) %>%  
  mutate(id=sequence(n())) %>%
  mutate(rank = rank(desc(number))) %>%
  filter(id <= 50)

globalData %>%
  select(dataset, label) %>%
  group_by(dataset, label) %>%
  filter(dataset=='AD20K') %>%
  semi_join(distributionSummaries, by=c('dataset', 'label')) %>%
  ggplot(aes(x=label, y=number)) +
    geom_bar(stat='identity', alpha=0.6, fill='blue', color='black') +
    facet_wrap(~ dataset, ncol=1, scales="free") +
    theme(axis.text.x = element_text(angle = 45, hjust=1))
```

# Number of objects per image

```{r, dpi=72, fig.width=12, fig.height=4}
globalData %>%
  group_by(dataset, imageId) %>%
  summarize(objects=n()) %>%
  ggplot(aes(x=dataset, y=objects, fill=dataset)) +
    geom_boxplot(alpha=0.6) +
    scale_y_log10() +
    coord_flip()
```

As we can see, the number of objects per image is very low in the case of VOC to be useful to use context cooccurrence as a source of information for object detection.

We can see that VG is densely annotated, having little to no images with fewer than 10 objects.

# Number of objects per image (descending) (Maybe better as a percentage of images...)

```{r, dpi=72, fig.width=12, fig.height=5}
objectsPerImage <- globalData %>%
  group_by(dataset, imageId) %>%
  summarize(objects=n()) %>%
  arrange(desc(objects)) %>%
  mutate(id=sequence(n())) %>%
  mutate(rank = rank(desc(objects))) %>%
  filter(id < 20000) 

objectsPerImage %>%
 ggplot(aes(x=id, y=objects, color=dataset)) +
   geom_smooth(stat='identity', alpha=0.7)
```

As the plot shows, the number of objects per image seem to converge asymptotically to the mean number of objects per image of the dataset. For COCO and VG that means a high percentage of the images contain above 10 or more objects, while for VOC just a few contains more than one object per image.

# Instances per label

```{r, dpi=72, fig.width=12, fig.height=4}
globalData %>%
  group_by(dataset, label) %>%
  summarize(objects=n()) %>%
  filter(label != "person") %>%
  ggplot(aes(x=dataset, y=objects, fill=dataset)) +
    geom_boxplot(alpha=0.6) +
    scale_y_log10() +
    coord_flip()
```

As expected due to the high number of labels and the noise in the dataset, most of the classes in Visual Genome contain just a few examples, while still containing a high number of classes with a very high number. 

# Number of instances per label (descending)

```{r, dpi=72, fig.width=12, fig.height=10}
instancesPerLabel <- globalData %>%
  group_by(dataset, label) %>%
  summarize(objects=n()) %>%
  arrange(desc(objects)) %>%
  mutate(id=sequence(n())) %>%
  mutate(rank = rank(desc(objects))) %>%
  filter(id < 1000) 

instancesPerLabel %>%
  select(label=id, instances=objects, dataset) %>%
  ggplot(aes(x=label, y=instances, color=dataset)) +
    geom_smooth(stat='identity', alpha=0.7) +
    scale_y_log10() +
    scale_x_log10()
```

# Label Analisys (Histogram)

```{r}
getSimilarities <- function(inputPath, fileName) {
  sampledPath <- paste(inputPath, paste('sampled', fileName, sep='_'), sep='/')
  
  sampledSimilarities <- NULL
  
  if (file.exists(sampledPath)) {
      sampledSimilarities <- read.csv(sampledPath)
  } else {
      similarities <- read.csv(paste(inputPath, fileName, sep='/'))
      sampledSimilarities <- sample_n(similarities, 1e5)
      write.csv(sampledSimilarities, sampledPath)
  }
  
  sampledSimilarities
}

ad20kSampleSimilarities <- getSimilarities('./analytics/', 'ad20k_similarities.csv')

```

```{r}
ad20kSampleSimilarities %>%
  arrange(desc(similarity)) %>%
  mutate(id = row_number()) %>%
  filter(similarity > 1e-3) %>%
  ggplot(aes(similarity)) +
    geom_histogram(binwidth = 0.05, fill='green', alpha=0.4, color='black')
```

# Label analysis [0.4, 0.5]

```{r}
similarityTable <- function(interv) {
  ad20kSampleSimilarities %>%
    arrange(desc(similarity)) %>%
    mutate(id = row_number()) %>%
    filter(similarity > interv, similarity < interv + 0.1) %>%
    sample_n(10) %>%
    select(label1, label2, similarity) %>%
    knitr::kable()
}

similarityTable(0.4)
```

# Label analysis [0.6, 0.7]

```{r}
similarityTable(0.6)
```

# Label analysis [0.8, 0.9]

```{r}
similarityTable(0.8)
```


# Top 10 labels (VOC)

```{r}
top10 <- instancesPerLabel %>%
  filter(id < 10) %>%
  select(dataset, label, instances=objects) %>%
  arrange(dataset, desc(instances))
```

```{r}
knitr::kable(filter(top10, dataset=="VOC"))
```

# Top 10 labels (COCO)

```{r}
knitr::kable(filter(top10, dataset=="COCO"))
```

# Top 10 labels (VG)

```{r}
knitr::kable(filter(top10, dataset=="VG"))
```


# Top 10 labels (Restricted VG)

```{r}
knitr::kable(filter(top10, dataset=="Restricted"))
```

# Top 10 labels (AD20K)

```{r}
knitr::kable(filter(top10, dataset=="AD20K"))
```

# Conditional independence analysis (I)

```{r}
getObjectAdjacency <- function(data, dsName, samples=NULL) {
  bnFileName <- paste('./analytics/', dsName, 'BN.csv', sep="_")
  
  if (file.exists(bnFileName)) {
    bnDf <- read.csv(bnFileName)
  } else {
    sampledIds <- data %>%
      filter(dataset == dsName) %>%
      select(imageId) %>%
      distinct()
    
    if (!is.null(samples)) {
      sampledIds <- sample_n(sampledIds, samples)
    }
    
    bnDf <- data %>%
      filter(dataset == dsName) %>%
      semi_join(sampledIds, by='imageId') %>%
      ungroup() %>%
      mutate(label = as.factor(as.character(label)), positive=1) %>%
      group_by(imageId, label) %>%
      summarize(positive=prod(positive)) %>%
      spread(label, positive, fill=0) %>%
      ungroup() %>%
      select(-imageId)
    
    bnDf <- as.data.frame(lapply(bnDf, as.factor))
    write.csv(bnDf, bnFileName)
  }

  bnDf
}

bnCoco <- getObjectAdjacency(globalData, "COCO")
bnVOC <- getObjectAdjacency(globalData, "VOC")
bnRestricted <- getObjectAdjacency(globalData, "Restricted")
bnAD20k <- getObjectAdjacency(globalData, "AD20K", 3000)
```

```{r}
entropy <- function(p) {
  -p * log(p)
}

createMIComputer <- function(dataset) {
  function (label1, label2) {
    res <- ci.test(label1, label2, data=dataset)
    res$statistic[[1]]
  }  
} 

computeMi <- function(dsName, ds, samples=NULL, force=FALSE) {
  miFileName <- paste('./analytics/', dsName, 'MI.csv', sep="_")
  
  if (file.exists(miFileName) && !force) {
    labelTuples <- read.csv(miFileName)
  } else {
    labels <- colnames(ds)
  
    cocoComputer <- createMIComputer(ds)
    
    labelTuples <- t(combn(labels, 2))
    labelTuples <- data.frame(l1=labelTuples[,1], l2=labelTuples[,2]) 
    
    if (!is.null(samples)) {
      labelTuples <- sample_n(labelTuples, samples)
    }
  
    labelTuples$mi <- mapply(cocoComputer, str_replace(labelTuples$l1, " ", "."), str_replace(labelTuples$l2, " ", "."))
    write.csv(labelTuples, miFileName)
    labelTuples$X <- 1:nrow(labelTuples)
  }
  
  labelTuples$dataset <- dsName
  p <- 1/length(levels(labelTuples$l1))
  labelTuples$h <- entropy(p)
  labelTuples$normMI <- labelTuples$mi / labelTuples$h
  labelTuples
  
}

miCoco <- computeMi("COCO", bnCoco)
miVOC <- computeMi("VOC", bnVOC)
miRestricted <- computeMi("Restricted", bnRestricted, 10000)
miAD20k <- computeMi("AD20K", bnAD20k, 5000)

miData <- rbind(miCoco, miVOC, miRestricted, miAD20k)
```

```{r, fig.width=10}
miData %>%
  ggplot(aes(x=normMI, fill=dataset)) +
    geom_histogram(bins=30, color='black') +
    scale_x_log10() +
    facet_wrap(~ dataset, scales = 'free_y', ncol = 2)
```

# Conditional independence analysis (II)

```{r, fig.width=10}
miData %>%
  ggplot(aes(x=dataset, y=normMI, fill=dataset)) +
    geom_boxplot() +
    scale_y_log10()
```

# Top 10 MI (VOC)

```{r}
showTop10MI <- function(datasetName) {
  miData %>%
    filter(dataset==datasetName) %>%
    arrange(desc(normMI)) %>%
    select(l1, l2, MI = normMI) %>%
    head(10) %>%
    knitr::kable()
}

showTop10MI("VOC")
```


# Top 10 MI (COCO)

```{r}
showTop10MI("COCO")
```

# Top 10 MI (Restricted VG)

```{r}
showTop10MI("Restricted")
```


# Top 10 MI (AD20k)

```{r}
showTop10MI("AD20K")
```

# Top labels ordered by MMI

```{r, fig.width=10, fig.height=6}
inverseMiData <- miData %>%
  mutate(l_back = l1, l1 = l2) %>%
  mutate(l2 = l_back) %>%
  select(l1, l2, normMI, dataset)

directMiData <- miData %>%
  select(l1, l2, normMI, dataset)

dualMiData <- rbind(directMiData, inverseMiData) %>%
  group_by(l1, dataset) %>%
  summarise(mmi = mean(normMI)) %>%
  arrange(desc(mmi)) %>%
  ungroup() %>%
  group_by(dataset) %>%
  mutate(i = row_number()) %>%
  filter(i < 100)
  
dualMiData %>%
  ggplot(aes(x=i, y=mmi, color=dataset)) +
    geom_line() +
    geom_point(alpha=0.7, shape=4) +
    scale_x_log10()
```


# LDA Topic analysis: number of non-zero words per model

```{r}
loadLdaTopics <- function(path) {
  folders <- list.files(path)
  
  completeData <- data.frame()
  
  for (folder in folders) {
    filename <- paste(folder, "_summary.csv", sep="")
    filepath <- paste(path, folder, filename, sep="/")
    
    folderData <- read.csv(filepath, col.names = c('id', 'key', 'p', 'object'))
    folderData$model <- folder
    
    completeData <- rbind(completeData, folderData)
  }
  
  completeData %>%
    mutate(model = as.factor(model))
}

VOCOPDData <- loadLdaTopics('/home/dani/Documentos/Proyectos/Doctorado/Datasets/VOCOPD/models/LDA_1000C')
VOCOPDData$dataset <- "VOC"

COCOOPDData <- loadLdaTopics('/home/dani/Documentos/Proyectos/Doctorado/Datasets/COCOOPD/models/LDA_1000C')
COCOOPDData$dataset <- "COCO"

VGOPDData <- loadLdaTopics('/home/dani/Documentos/Proyectos/Doctorado/Datasets/VGOPD/models/LDA_1000C')
VGOPDData$dataset <- "VG"

Ad20kOPDData <- loadLdaTopics('/home/dani/Documentos/Proyectos/Doctorado/Datasets/ADE20KOPD/models/LDA_1000C')
Ad20kOPDData$dataset <- "AD20K"

RestrictedOPDData <- loadLdaTopics('/home/dani/Documentos/Proyectos/Doctorado/Datasets/RestrictedOPD/models/LDA_1000C')
RestrictedOPDData$dataset <- "Restricted"

opdData <- rbind(VOCOPDData, COCOOPDData, VGOPDData, RestrictedOPDData, Ad20kOPDData)
```

```{r, dpi=72, fig.width=12, fig.height=8}
threshold <- 0.00001

opdData %>%
  mutate(positive=ifelse(p > threshold, TRUE, FALSE)) %>%
  group_by(dataset, model, key) %>%
  summarize(positives=sum(positive)) %>%
  ggplot(aes(x=model, y=positives, group=model, fill=model)) +
    facet_wrap(~ dataset, scales="free", ncol=2) +
    geom_boxplot(alpha=0.7) +
    theme(axis.text.x = element_text(angle = 45, hjust=1)) +
    coord_flip()
```

# LDA Topic analysis: topic probability distribution per dataset

```{r, dpi=72, fig.width=12, fig.height=8}
threshold <- 0.00001

opdData %>%
  filter(p > threshold) %>%
  ggplot(aes(x=p, fill=dataset)) +
    facet_wrap(~ dataset, scales="free", ncol=2) +
    geom_histogram(alpha=0.7, color="black", binwidth = 0.1) +
    theme(axis.text.x = element_text(angle = 45, hjust=1))
```

# LDA Topic analysis: topic probability distribution per LDA model metaparameters

```{r, dpi=72, fig.width=12, fig.height=8}
threshold <- 0.00001

opdData %>%
  filter(p > threshold) %>%
  ggplot(aes(x=p, fill=model)) +
    facet_wrap(~ model, scales="free", ncol=3) +
    geom_histogram(alpha=0.7, color="black", binwidth = 0.1) +
    theme(axis.text.x = element_text(angle = 45, hjust=1))
```


# LDA Topic Analysis: VOC Topics

```{r}
threshold <- 0.05

spreadPositives <- opdData %>%
  mutate(positive=ifelse(p > threshold, TRUE, FALSE), dataset=as.factor(dataset)) %>%
  group_by(dataset, model, key) %>%
  summarize(positives=sum(positive)) %>%
  filter(positives > 4) %>%
  arrange(desc(positives))

ldaModelData <- opdData %>% 
  mutate(dataset=as.factor(dataset)) %>%
  semi_join(spreadPositives, by=c('dataset', 'model', 'key')) %>%
  filter(p > threshold) %>%
  select(dataset, model, key, object, p) %>%
  group_by(dataset, model, key) %>%
  summarize(words = paste(object, collapse=", "), prob=paste(p, collapse=", ")) %>%
  ungroup() %>%
  select(dataset, model, key, words, prob) %>%
  gather(attribute, values, -key, -model, -dataset) 

```


```{r}
modelIds <- ldaModelData %>%
  filter(dataset == 'VOC') %>%
  group_by(dataset, model, key) %>%
  summarize(n = n()) %>%
  ungroup() %>%
  sample_n(5)


ldaModelData %>%
  semi_join(modelIds, by=c('dataset', 'model', 'key')) %>%
  select(model, key, values) %>%
  knitr::kable() 
```

# LDA Topic Analysis: VOC Examples LDA_150_2 (6)

```{r, out.width="35%"}
baseVOCPathEx <- '/home/dani/Documentos/Proyectos/Doctorado/Datasets/VOCOPD/models/LDA_1000C'
modelEx <- 'LDA_150_2'

getVOCEx <- function(folder, number) {
  paste(baseVOCPathEx, modelEx, 'examples_201911061304', folder, number, sep='/')
}

examples <- c(getVOCEx('6', 'ex_0-6.jpg'),
              getVOCEx('6', 'ex_18-6.jpg'),
              getVOCEx('6', 'ex_82-6.jpg'),
              getVOCEx('6', 'ex_98-6.jpg')
              )
 
knitr::include_graphics(examples)
```

# LDA Topic Analysis: COCO

```{r}
modelIds <- ldaModelData %>%
  filter(dataset == 'COCO') %>%
  group_by(dataset, model, key) %>%
  summarize(n = n()) %>%
  ungroup() %>%
  sample_n(5)


ldaModelData %>%
  semi_join(modelIds, by=c('dataset', 'model', 'key')) %>%
  select(model, key, values) %>%
  knitr::kable() 
```


# LDA Topic Analysis: COCO Examples LDA_25_2 (10)

```{r, out.width="35%"}
baseCOCOPathEx <- '/home/dani/Documentos/Proyectos/Doctorado/Datasets/COCOOPD/models/LDA_1000C'
modelEx <- 'LDA_25_2'

getCocoEx <- function(folder, number) {
  paste(baseCOCOPathEx, modelEx, 'examples_201911061154', folder, number, sep='/')
}

examples <- c(getCocoEx('10', 'ex_17-10_15_0_1_2_3_4_5_6_7_8_9_11_12_13_14_16_17_18_19_20_21_22_23_24.jpg'),
              getCocoEx('10', 'ex_62-10_4_15.jpg'),
              getCocoEx('10', 'ex_234-10_17_0_1_2_3_4_5_6_7_8_9_11_12_13_14_15_16_18_19_20_21_22_23_24.jpg'),
              getCocoEx('10', 'ex_588-10_15_0_1_2_3_4_5_6_7_8_9_11_12_13_14_16_17_18_19_20_21_22_23_24.jpg')
              )
 
knitr::include_graphics(examples)
```


# LDA Topic Analysis: Visual Genome

```{r}
modelIds <- ldaModelData %>%
  filter(dataset == 'VG') %>%
  group_by(dataset, model, key) %>%
  summarize(n = n()) %>%
  ungroup() %>%
  sample_n(5)


ldaModelData %>%
  semi_join(modelIds, by=c('dataset', 'model', 'key')) %>%
  select(model, key, values) %>%
  knitr::kable() 
```

# LDA Topic Analysis: Restricted Visual Genome

```{r}
modelIds <- ldaModelData %>%
  filter(dataset == 'Restricted') %>%
  group_by(dataset, model, key) %>%
  summarize(n = n()) %>%
  ungroup() %>%
  sample_n(5)


ldaModelData %>%
  semi_join(modelIds, by=c('dataset', 'model', 'key')) %>%
  select(model, key, values) %>%
  knitr::kable() 
```

# LDA Topic Analysis: Restricted VG Examples LDA_100_16 (3)

```{r, out.width="35%"}
baseRestrictedPathEx <- '/home/dani/Documentos/Proyectos/Doctorado/Datasets/RestrictedOPD/models/LDA_1000C'
modelEx <- 'LDA_100_16'

getRestrictedEx <- function(folder, number) {
  paste(baseRestrictedPathEx, modelEx, 'examples_201910231744', folder, number, sep='/')
}

examples <- c(getRestrictedEx('3', 'ex_51-3_5_7_9_17_20_22_27_34_44_52_64_70.jpg'),
              getRestrictedEx('3', 'ex_63-3_16_34_64_71.jpg'),
              getRestrictedEx('3', 'ex_95-3_5_9_17_20_24_34_39_51_67_82_95.jpg'),
              getRestrictedEx('3', 'ex_530-3_16_17_24_64_67_68_90_96.jpg')
              )
 
knitr::include_graphics(examples)
```

# LDA Topic Analysis: Restricted VG Examples LDA_100_16 (9)

```{r, out.width="35%"}
baseRestrictedPathEx <- '/home/dani/Documentos/Proyectos/Doctorado/Datasets/RestrictedOPD/models/LDA_1000C'
modelEx <- 'LDA_100_16'

getRestrictedEx <- function(folder, number) {
  paste(baseRestrictedPathEx, modelEx, 'examples_201910240653', folder, number, sep='/')
}

examples <- c(getRestrictedEx('9', 'ex_2-9_34_16_24_71_3_84_59_4_45.jpg'),
              getRestrictedEx('9', 'ex_113-9_71_16_17_34_7_52_3_84_24_31_85_66.jpg'),
              getRestrictedEx('9', 'ex_123-9_3_36_34_71_95_76_1_68_24_21_67_79_72_50_31_11_64_12.jpg'),
              getRestrictedEx('9', 'ex_512-9_44_57_17_34_70_58_47_82_76_37.jpg')
              )
 
knitr::include_graphics(examples)
```

# LDA Topic Analysis: AD20K

```{r}
modelIds <- ldaModelData %>%
  filter(dataset == 'AD20K') %>%
  group_by(dataset, model, key) %>%
  summarize(n = n()) %>%
  ungroup() %>%
  sample_n(5)


ldaModelData %>%
  semi_join(modelIds, by=c('dataset', 'model', 'key')) %>%
  select(model, key, values) %>%
  knitr::kable()  
```

# LDA Topic Analysis: AD20k LDA_25_8 (1)

```{r, out.width="35%"}
baseRestrictedPathEx <- '/home/dani/Documentos/Proyectos/Doctorado/Datasets/ADE20KOPD/models/LDA_1000C'
modelEx <- 'LDA_25_8'

getRestrictedEx <- function(folder, number) {
  paste(baseRestrictedPathEx, modelEx, 'examples', folder, number, sep='/')
}

examples <- c(getRestrictedEx('1', 'ex_14-1_23_11.jpg'),
              getRestrictedEx('1', 'ex_96-1_23.jpg'),
              getRestrictedEx('1', 'ex_192-1_23_22_20_5_10_6.jpg'),
              getRestrictedEx('1', 'ex_265-1_23_5_7_0_24.jpg')
              )
 
knitr::include_graphics(examples)
```

# LDA Topic Analysis: AD20k LDA_25_8 (9)

```{r, out.width="35%"}
baseRestrictedPathEx <- '/home/dani/Documentos/Proyectos/Doctorado/Datasets/ADE20KOPD/models/LDA_1000C'
modelEx <- 'LDA_25_8'

getRestrictedEx <- function(folder, number) {
  paste(baseRestrictedPathEx, modelEx, 'examples', folder, number, sep='/')
}

examples <- c(getRestrictedEx('9', 'ex_37-9_21_3_6_2_22.jpg'),
              getRestrictedEx('9', 'ex_121-9_10_21_6_8.jpg'),
              getRestrictedEx('9', 'ex_228-9_6_2.jpg'),
              getRestrictedEx('9', 'ex_273-9.jpg')
              )
 
knitr::include_graphics(examples)
```

# Next steps: topic detectors

Use standard classifiers to detect topic distribution: LDA Model provides topic distribution based on the objects in the image and a CNN tries to get the distribution 
directly.


# Next steps: use of inferenced data to improve object recognition

Independent of the previous step, can be tested using the label and the LDA model to get an optimal value (not real but help to test the inference process itself)

















